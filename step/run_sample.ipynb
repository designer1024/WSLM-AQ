{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMQVMjDJ7mIeRo+u4sGfK/Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**From image-level to pixel-level labeling: A weakly-supervised learning method for identifying aquaculture ponds using iterative anti-adversarial attacks guided by aquaculture features**\n","\n","Author: Boyi Li, Adu Gong, Jiaming Zhang, Zexin Fu\n","\n","Update: 2024/07/17\n","\n","\n","After completing the dataset preparation stage, you should have two folders: one for storing output aquaculture imagery and another for storing output non-aquaculture imagery. These images will be used for pre-training the classification model, generating pseudo-labels, and implementing semantic segmentation.\n","\n","This is the code used in the paper, and it can be run on Google Colab after editing the code."],"metadata":{"id":"mLFAlcCeX2RR"}},{"cell_type":"markdown","source":["#Step 1: Model pre-training\n","## Input\n","A folder contains both aquaculture and non-aquaculture imagery. The examplary structure of the folder is as follows:\n","\n","**/…/WSLM-AQ/inputs/dataset_cls/**\n","\n","*0: a folder for non-aquaculture imagery*\n","\n","*1: a folder for aquaculture imagery*\n","\n","##Output\n","\n","A folder contains well-trained model and other output files. The sample structure of the folder is as follows:\n","\n","**/…/WSLM-AQ/models/model_cls/**\n","\n","*config.yml: config information*\n","\n","*log_train.csv：model training log (only available when train_mode == 'True')*\n","\n","*log_val.csv：model validation log (only available when train_mode == 'False')*\n","\n","*result.jpg: result figure\n","\n","*model_oa.pth: well-trained model parameters with best oa*\n","\n","*model_loss.pth: well-trained model parameters with best loss*"],"metadata":{"id":"X8gC6NNvX3Yz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","import os\n","import torch\n","\n","#todo: Input your working directory\n","workdir='/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/step'\n","os.chdir(workdir)\n","\n","#todo: Set your parameters according to the tips in train_my_classification.py\n","!python train_my_classification.py \\\n","--name  'model_cls'\\\n","--device 'cuda'\\\n","--dataset 'dataset_cls'\\\n","--work_dir '/content/drive/MyDrive/Colab Notebooks/WSLM-AQ'\\\n","--package_dirs \"['/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/packages/packages_dl']\"\\\n","--img_ext '.tif'\\\n","--input_channel_list '[0,1,2,3]'\\\n","--num_classes 2\\\n","--transform True\\\n","--train_transform_methods \"{'one_hot':{'num_classes':2}}\"\\\n","--val_transform_methods \"{'one_hot':{'num_classes':2}}\"\\\n","--batch_size 8\\\n","--arch 'models.classification.vgg'\\\n","--arch_parameters \"{'input_size':(4,256,256),'num_classes':2,'model_name':'vgg19'}\"\\\n","--pretrain_backbone False\\\n","--pretrain_path ''\\\n","--train_mode 'True'\\\n","--epochs 20\\\n","--loss 'BinaryCrossEntropyWithLogits'\\\n","--optimizer 'Adam'\\\n","--optimizer_params \"{'lr':0.0001}\"\\\n","--early_stopping 10\\\n","--best_metric 'loss'"],"metadata":{"id":"L_khimKIY0V8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Step 2: Pseudo-label generation\n","\n","## Input\n","\n","img_cam_dir: A folder of input imagery for generating pseudo-labels.\n","\n","pretrain_dir: Folder for pre-trained model and other files.\n","\n","##Output\n","\n","A folder contains output pseudo-labels. The examplary structure of the folder is as follows:\n","\n","**/…/WSLM-AQ/models/model_cls/cam/**\n","\n","*result: output imagery with pseudo-labels, which can be used for semantic segmentation*\n","\n","*config_make_cam.yml：config information*"],"metadata":{"id":"Zx3uVX-taH_N"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","import os\n","import torch\n","\n","#todo: Input your working directory\n","workdir='/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/step'\n","os.chdir(workdir)\n","\n","#todo: Set your parameters according to the tips in make_cam.py\n","!python make_cam.py \\\n","--device 'cuda'\\\n","--package_dirs \"['/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/packages/packages_dl']\"\\\n","--pretrain_dir '/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/models/model_cls'\\\n","--model_name 'model_loss.pth'\\\n","--outputdir_name 'cam'\\\n","--img_cam_dir '/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/inputs/dataset_cls/train'\\\n","--output_type '.tif'\\\n","--classes_pos \"[1]\"\\\n","--water_channels -2\\\n","--label_channels -1\\\n","--scales '(1.0, 0.5, 0.75, 1.25, 1.5, 1.75, 2.0)'\\\n","--cam 'models.segmentation.gradcam'\\\n","--target_layer \"['layer5.12']\"\\\n","--target_layer_weight \"[1]\"\\\n","--adv_iter 20\\\n","--score_th 0.5\\\n","--AD_coeff 7\\\n","--AD_stepsize 0.08\\\n","--flip_augmentation 'True'\\\n","--use_water 'True'\\\n","--water_threshold 0.3\\\n","--suppressing_classes 'True'\\\n","--add_discriminative 'True'\\\n","--water_for_discriminative 'True'\\\n","--non_water_for_discriminative 'True'\\\n","--AD_coeff2 7"],"metadata":{"id":"VwTiBsuhaIH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Step 3: Semantic segmentation\n","\n","## Input\n","\n","A folder contains both aquaculture and non-aquaculture imagery. The sample structure of the folder is as follows:\n","\n","**/…/WSLM-AQ/inputs/dataset_seg/**\n","\n","*0: a folder for non-aquaculture imagery with labels*\n","\n","*1: a folder for aquaculture imagery with labels*\n","\n","A folder contains well-trained model and other output files. The examplary structure of the folder is as follows:\n","\n","**/…/WSLM-AQ/models/model_seg/**\n","\n","*config.yml: config information*\n","\n","*log_train.csv：model training log (only available when train_mode == 'True')*\n","\n","*log_val.csv：model validation log (only available when train_mode == 'False')*\n","\n","*result.jpg: result figure*\n","\n","*model_iou.pth: well-trained model parameters with best oa (only available when best_metric == 'iou')*\n","\n","*model_loss.pth: well-trained model parameters with best oa (only available when best_metric == 'loss')*\n","\n","*output: output labels (only available when train_mode == 'False')*"],"metadata":{"id":"UJRTRL0QbCV4"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","import os\n","import torch\n","\n","#todo: Input your working directory\n","workdir='/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/step'\n","os.chdir(workdir)\n","\n","#todo: Set your parameters according to the tips in train_my_segmentation.py\n","!python train_my_segmentation.py \\\n","--name  'model_seg'\\\n","--device 'cuda'\\\n","--dataset 'dataset_cls'\\\n","--work_dir '/content/drive/MyDrive/Colab Notebooks/WSLM-AQ'\\\n","--package_dirs \"['/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/packages/packages_dl']\"\\\n","--img_ext '.tif'\\\n","--input_channel_list '[0,1,2,3]'\\\n","--pos_classes '[1]'\\\n","--neg_classes '[0]'\\\n","--transform 'True'\\\n","--train_transform_methods \"{'one_hot_segmentation_binary':{'test':None}}\"\\\n","--val_transform_methods \"{'one_hot_segmentation_binary':{'test':None}}\"\\\n","--batch_size_train 8\\\n","--batch_size_val 1\\\n","--arch 'models.segmentation.unet_vgg'\\\n","--arch_parameters \"{'input_size':(4,256,256),'num_classes':2,'model_name':'vgg19'}\"\\\n","--pretrain_backbone 'True'\\\n","--pretrain_path '/content/drive/MyDrive/Colab Notebooks/WSLM-AQ/models/model_cls/model_loss.pth'\\\n","--train_mode 'True'\\\n","--epochs 40\\\n","--optimizer 'Adam'\\\n","--optimizer_params \"{'lr':0.001}\"\\\n","--loss 'BinaryCrossEntropyWithLogits'\\\n","--early_stopping 10\\\n","--neg_for_train 'True'\\\n","--update 'True'\\\n","--update_epoch 20\\\n","--best_metric 'loss'"],"metadata":{"id":"zyyH_tcBbCfl"},"execution_count":null,"outputs":[]}]}